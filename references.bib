@misc{nie_time_2023,
	title = {A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
	url = {http://arxiv.org/abs/2211.14730},
	doi = {10.48550/arXiv.2211.14730},
	shorttitle = {A Time Series is Worth 64 Words},
	abstract = {We propose an efficient design of Transformer-based models for multivariate time series forecasting and self-supervised representation learning. It is based on two key components: (i) segmentation of time series into subseries-level patches which are served as input tokens to Transformer; (ii) channel-independence where each channel contains a single univariate time series that shares the same embedding and Transformer weights across all the series. Patching design naturally has three-fold benefit: local semantic information is retained in the embedding; computation and memory usage of the attention maps are quadratically reduced given the same look-back window; and the model can attend longer history. Our channel-independent patch time series Transformer ({PatchTST}) can improve the long-term forecasting accuracy significantly when compared with that of {SOTA} Transformer-based models. We also apply our model to self-supervised pre-training tasks and attain excellent fine-tuning performance, which outperforms supervised training on large datasets. Transferring of masked pre-trained representation on one dataset to others also produces {SOTA} forecasting accuracy. Code is available at: https://github.com/yuqinie98/{PatchTST}.},
	number = {{arXiv}:2211.14730},
	publisher = {{arXiv}},
	author = {Nie, Yuqi and Nguyen, Nam H. and Sinthong, Phanwadee and Kalagnanam, Jayant},
	urldate = {2024-01-12},
	date = {2023-03-05},
	eprinttype = {arxiv},
	eprint = {2211.14730 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/louis/Zotero/storage/RG62MCUF/Nie et al. - 2023 - A Time Series is Worth 64 Words Long-term Forecasting with Transformers.pdf:application/pdf;arXiv.org Snapshot:/home/louis/Zotero/storage/7ZURFNQT/2211.html:text/html},
}

@article{schroer_systematic_2021,
	title = {A Systematic Literature Review on Applying {CRISP}-{DM} Process Model},
	volume = {181},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050921002416},
	doi = {10.1016/j.procs.2021.01.199},
	series = {{CENTERIS} 2020 - International Conference on {ENTERprise} Information Systems / {ProjMAN} 2020 - International Conference on Project {MANagement} / {HCist} 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, {CENTERIS}/{ProjMAN}/{HCist} 2020},
	abstract = {{CRISP}-{DM} is the de-facto standard and an industry-independent process model for applying data mining projects. Twenty years after its release in 2000, we would like to provide a systematic literature review of recent studies published in {IEEE}, {ScienceDirect} and {ACM} about data mining use cases applying {CRISP}-{DM}. We give an overview of the research focus, current methodologies, best practices and possible gaps in conducting the six phases of {CRISP}-{DM}. The main findings are that {CRISP}-{DM} is still a de-factor standard in data mining, but there are challenges since the most studies do not foresee a deployment phase. The contribution of our paper is to identify best practices and process phases in which data mining analysts can be better supported. Further contribution is a template for structuring and releasing {CRISP}-{DM} studies.},
	pages = {526--534},
	journaltitle = {Procedia Computer Science},
	shortjournal = {Procedia Computer Science},
	author = {Schröer, Christoph and Kruse, Felix and Gómez, Jorge Marx},
	urldate = {2024-01-03},
	date = {2021-01-01},
	keywords = {{CRISP}-{DM}, Data Mining, Deployment, Literature Review, Process Methodology},
	file = {ScienceDirect Full Text PDF:/home/louis/Zotero/storage/VDITES2Q/Schröer et al. - 2021 - A Systematic Literature Review on Applying CRISP-DM Process Model.pdf:application/pdf;ScienceDirect Snapshot:/home/louis/Zotero/storage/HQMIMVNW/S1877050921002416.html:text/html},
}

@inproceedings{gu_hippo_2020,
	title = {{HiPPO}: Recurrent Memory with Optimal Polynomial Projections},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/102f0bb6efb3a6128a3c750dd16729be-Abstract.html},
	shorttitle = {{HiPPO}},
	abstract = {A central problem in learning from sequential data is representing cumulative
history in an incremental fashion as more data is processed. We introduce a general framework ({HiPPO}) for the online compression of continuous signals and discrete time series by projection onto polynomial bases. Given a measure that specifies the importance of each time step in the past, {HiPPO} produces an optimal solution to a natural online function approximation problem. As special cases, our framework yields a short derivation of the recent Legendre Memory Unit ({LMU}) from first principles, and generalizes the ubiquitous gating mechanism of recurrent neural networks such as {GRUs}. This formal framework yields a new memory update mechanism ({HiPPO}-{LegS}) that scales through time to remember all history, avoiding priors on the timescale. {HiPPO}-{LegS} enjoys the theoretical benefits of timescale robustness, fast updates, and bounded gradients. By incorporating the memory dynamics into recurrent neural networks, {HiPPO} {RNNs} can empirically capture complex temporal dependencies. On the benchmark permuted {MNIST} dataset, {HiPPO}-{LegS} sets a new state-of-the-art accuracy of 98.3\%. Finally, on a novel trajectory classification task testing robustness to out-of-distribution timescales and missing data, {HiPPO}-{LegS} outperforms {RNN} and neural {ODE} baselines by 25-40\% accuracy.},
	pages = {1474--1487},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Gu, Albert and Dao, Tri and Ermon, Stefano and Rudra, Atri and Ré, Christopher},
	urldate = {2023-12-11},
	date = {2020},
	file = {Full Text PDF:/home/louis/Zotero/storage/FVGF7UYB/Gu et al. - 2020 - HiPPO Recurrent Memory with Optimal Polynomial Pr.pdf:application/pdf},
}

@online{noauthor_paperskalman_nodate,
	title = {papers/kalman filter/A New Approach to Linear Filtering and Prediction Problems.pdf at master · {yyccR}/papers},
	url = {https://github.com/yyccR/papers/blob/master/kalman%20filter/A%20New%20Approach%20to%20Linear%20Filtering%20and%20Prediction%20Problems.pdf},
	abstract = {Some papers that have been of great help in my work, especially in the fields of {ML} and {DL}. - {yyccR}/papers},
	titleaddon = {{GitHub}},
	urldate = {2023-12-11},
	langid = {english},
}

@software{noauthor_state-spacess4_2023,
	title = {state-spaces/s4},
	rights = {Apache-2.0},
	url = {https://github.com/state-spaces/s4},
	abstract = {Structured state space sequence models},
	publisher = {state-spaces},
	urldate = {2023-12-11},
	date = {2023-12-11},
	note = {original-date: 2021-11-03T15:33:53Z},
	keywords = {pytorch, sequence-models, state-space-models},
}

@misc{gu_mamba_2023,
	title = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
	url = {http://arxiv.org/abs/2312.00752},
	doi = {10.48550/arXiv.2312.00752},
	shorttitle = {Mamba},
	abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models ({SSMs}) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the {SSM} parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective {SSMs} into a simplified end-to-end neural network architecture without attention or even {MLP} blocks (Mamba). Mamba enjoys fast inference (5\${\textbackslash}times\$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
	number = {{arXiv}:2312.00752},
	publisher = {{arXiv}},
	author = {Gu, Albert and Dao, Tri},
	urldate = {2023-12-11},
	date = {2023-12-01},
	eprinttype = {arxiv},
	eprint = {2312.00752 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/louis/Zotero/storage/VSQZPYC4/Gu und Dao - 2023 - Mamba Linear-Time Sequence Modeling with Selectiv.pdf:application/pdf;arXiv.org Snapshot:/home/louis/Zotero/storage/5ZNWWDAB/2312.html:text/html},
}

@article{zhou_informer_2021,
	title = {Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},
	volume = {35},
	rights = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/17325},
	doi = {10.1609/aaai.v35i12.17325},
	shorttitle = {Informer},
	abstract = {Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting ({LSTF}) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to {LSTF}, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for {LSTF}, named Informer, with three distinctive characteristics: (i) a {ProbSparse} self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences' dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the {LSTF} problem.},
	pages = {11106--11115},
	number = {12},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
	urldate = {2023-12-11},
	date = {2021-05-18},
	langid = {english},
	note = {Number: 12},
	keywords = {Energy, Environment \& Sustainability},
	file = {Full Text PDF:/home/louis/Zotero/storage/D8KKJJEL/Zhou et al. - 2021 - Informer Beyond Efficient Transformer for Long Se.pdf:application/pdf},
}

@misc{gu_efficiently_2022,
	title = {Efficiently Modeling Long Sequences with Structured State Spaces},
	url = {http://arxiv.org/abs/2111.00396},
	doi = {10.48550/arXiv.2111.00396},
	abstract = {A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including {RNNs}, {CNNs}, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of \$10000\$ or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental state space model ({SSM}) {\textbackslash}( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) {\textbackslash}), and showed that for appropriate choices of the state matrix {\textbackslash}( A {\textbackslash}), this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the {SSM}, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning {\textbackslash}( A {\textbackslash}) with a low-rank correction, allowing it to be diagonalized stably and reducing the {SSM} to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91{\textbackslash}\% accuracy on sequential {CIFAR}-10 with no data augmentation or auxiliary losses, on par with a larger 2-D {ResNet}, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation \$60{\textbackslash}times\$ faster (iii) {SoTA} on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.},
	number = {{arXiv}:2111.00396},
	publisher = {{arXiv}},
	author = {Gu, Albert and Goel, Karan and Ré, Christopher},
	urldate = {2023-12-11},
	date = {2022-08-05},
	eprinttype = {arxiv},
	eprint = {2111.00396 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/louis/Zotero/storage/42VBKP5C/Gu et al. - 2022 - Efficiently Modeling Long Sequences with Structure.pdf:application/pdf;arXiv.org Snapshot:/home/louis/Zotero/storage/2PL9UVYI/2111.html:text/html},
}

@article{li_generative_2022,
	title = {Generative Time Series Forecasting with Diffusion, Denoise, and Disentanglement},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/91a85f3fb8f570e6be52b333b5ab017a-Abstract-Conference.html},
	pages = {23009--23022},
	journaltitle = {Advances in Neural Information Processing Systems},
	author = {Li, Yan and Lu, Xinjiang and Wang, Yaqing and Dou, Dejing},
	urldate = {2023-11-08},
	date = {2022-12-06},
	langid = {english},
	file = {Full Text PDF:/home/louis/Zotero/storage/BYAZZH49/Li et al. - 2022 - Generative Time Series Forecasting with Diffusion,.pdf:application/pdf},
}

@online{tay_long_2020,
	title = {Long Range Arena: A Benchmark for Efficient Transformers},
	url = {https://arxiv.org/abs/2011.04006v1},
	shorttitle = {Long Range Arena},
	abstract = {Transformers do not scale very well to long sequence lengths largely because of quadratic self-attention complexity. In the recent months, a wide spectrum of efficient, fast Transformers have been proposed to tackle this problem, more often than not claiming superior or comparable model quality to vanilla Transformer models. To this date, there is no well-established consensus on how to evaluate this class of models. Moreover, inconsistent benchmarking on a wide spectrum of tasks and datasets makes it difficult to assess relative model quality amongst many models. This paper proposes a systematic and unified benchmark, {LRA}, specifically focused on evaluating model quality under long-context scenarios. Our benchmark is a suite of tasks consisting of sequences ranging from \$1K\$ to \$16K\$ tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. We systematically evaluate ten well-established long-range Transformer models (Reformers, Linformers, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on our newly proposed benchmark suite. {LRA} paves the way towards better understanding this class of efficient Transformer models, facilitates more research in this direction, and presents new challenging tasks to tackle. Our benchmark code will be released at https://github.com/google-research/long-range-arena.},
	titleaddon = {{arXiv}.org},
	author = {Tay, Yi and Dehghani, Mostafa and Abnar, Samira and Shen, Yikang and Bahri, Dara and Pham, Philip and Rao, Jinfeng and Yang, Liu and Ruder, Sebastian and Metzler, Donald},
	urldate = {2024-01-02},
	date = {2020-11-08},
	langid = {english},
	file = {Full Text PDF:/home/louis/Zotero/storage/VCUFQCSS/Tay et al. - 2020 - Long Range Arena A Benchmark for Efficient Transformers.pdf:application/pdf},
}

@article{benidis_deep_2022,
	title = {Deep Learning for Time Series Forecasting: Tutorial and Literature Survey},
	volume = {55},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3533382},
	doi = {10.1145/3533382},
	shorttitle = {Deep Learning for Time Series Forecasting},
	abstract = {Deep learning based forecasting methods have become the methods of choice in many applications of time series prediction or forecasting often outperforming other approaches. Consequently, over the last years, these methods are now ubiquitous in large-scale industrial forecasting applications and have consistently ranked among the best entries in forecasting competitions (e.g., M4 and M5). This practical success has further increased the academic interest to understand and improve deep forecasting methods. In this article we provide an introduction and overview of the field: We present important building blocks for deep forecasting in some depth; using these building blocks, we then survey the breadth of the recent deep forecasting literature.},
	pages = {121:1--121:36},
	number = {6},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Benidis, Konstantinos and Rangapuram, Syama Sundar and Flunkert, Valentin and Wang, Yuyang and Maddix, Danielle and Turkmen, Caner and Gasthaus, Jan and Bohlke-Schneider, Michael and Salinas, David and Stella, Lorenzo and Aubet, François-Xavier and Callot, Laurent and Januschowski, Tim},
	urldate = {2023-11-08},
	date = {2022-12-07},
	keywords = {forecasting, neural networks, Time series},
	file = {Full Text PDF:/home/louis/Zotero/storage/WQJ3WJJ7/Benidis et al. - 2022 - Deep Learning for Time Series Forecasting Tutoria.pdf:application/pdf},
}

@article{murphy_univariate_2022,
	title = {Univariate vs Multivariate Time Series Forecasting with Transformers},
	url = {https://openreview.net/forum?id=GpW327gxLTF},
	abstract = {Multivariate time series forecasting is a challenging problem and a number of Transformer-based long-term time series forecasting models have been developed to tackle it. These models, however, are impeded by the additional information available in multivariate forecasting. In this paper we propose a simple univariate setting as an alternative method for producing multivariate forecasts. The univariate model is trained on each individual dimension of the time series. This single model is then used to forecast each dimension of the multivariate forecast in turn. A comparative study shows that our setting outperforms state-of-the-art Transformers in the multivariate setting in benchmark datasets. To investigate why, we set three hypotheses and verify them via an empirical study, which leads to a criterion for when our univariate setting is likely to lead to better performance and reveals flaws in the current multivariate Transformers for long-term time series forecasting.},
	author = {Murphy, William Michael John and Chen, Ke},
	urldate = {2023-12-12},
	date = {2022-09-29},
	langid = {english},
	file = {Full Text PDF:/home/louis/Zotero/storage/R8K2EHRY/Murphy and Chen - 2022 - Univariate vs Multivariate Time Series Forecasting.pdf:application/pdf},
}

@article{wen_recent_2022,
	title = {Recent advances and trends of predictive maintenance from data-driven machine prognostics perspective},
	volume = {187},
	issn = {0263-2241},
	url = {https://www.sciencedirect.com/science/article/pii/S0263224121011805},
	doi = {10.1016/j.measurement.2021.110276},
	abstract = {In the Engineering discipline, prognostics play an essential role in improvingsystemsafety, reliability and enabling predictive maintenance decision-making. Due to the adoption of emerging sensing techniques and big data analytics tools, data-driven prognostic approaches are gaining popularity. This paper aims to deliver an extensive review of recent advances and trends of data-driven machine prognostics, with a focus on their applications in practice. The primary purpose of this review is to categorize existing literature and report the latest research progress and directions to support researchers and practitioners in acquiring a clear comprehension of the subject area. This paper first summarizes fundamental methodologies on data-driven approaches for predictive maintenance. Then, the article further conducts a comprehensive investigation on the different fields of applications of machine prognostics. Finally, a discussion on the challenges, opportunities, and future trends of predictive maintenance is presented to conclude this paper.},
	pages = {110276},
	journaltitle = {Measurement},
	shortjournal = {Measurement},
	author = {Wen, Yuxin and Fashiar Rahman, Md. and Xu, Honglun and Tseng, Tzu-Liang Bill},
	urldate = {2023-12-21},
	date = {2022-01-01},
	keywords = {Machine learning, Condition-based maintenance, Machine prognostics, Predictive maintenance, Prognostics and health management, Remaining useful life},
	file = {ScienceDirect Snapshot:/home/louis/Zotero/storage/59QAKQUY/S0263224121011805.html:text/html},
}

@article{carvalho_systematic_2019,
	title = {A systematic literature review of machine learning methods applied to predictive maintenance},
	volume = {137},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835219304838},
	doi = {10.1016/j.cie.2019.106024},
	abstract = {The amount of data extracted from production processes has increased exponentially due to the proliferation of sensing technologies. When processed and analyzed, data can bring out valuable information and knowledge from manufacturing process, production system and equipment. In industries, equipment maintenance is an important key, and affects the operation time of equipment and its efficiency. Thus, equipment faults need to be identified and solved, avoiding shutdown in the production processes. Machine Learning ({ML}) methods have been emerged as a promising tool in Predictive Maintenance ({PdM}) applications to prevent failures in equipment that make up the production lines in the factory floor. However, the performance of {PdM} applications depends on the appropriate choice of the {ML} method. The aim of this paper is to present a systematic literature review of {ML} methods applied to {PdM}, showing which are being explored in this field and the performance of the current state-of-the-art {ML} techniques. This review focuses on two scientific databases and provides a useful foundation on the {ML} techniques, their main results, challenges and opportunities, as well as it supports new research works in the {PdM} field.},
	pages = {106024},
	journaltitle = {Computers \& Industrial Engineering},
	shortjournal = {Computers \& Industrial Engineering},
	author = {Carvalho, Thyago P. and Soares, Fabrízzio A. A. M. N. and Vita, Roberto and Francisco, Roberto da P. and Basto, João P. and Alcalá, Symone G. S.},
	urldate = {2023-12-19},
	date = {2019-11-01},
	keywords = {Machine learning, Predictive maintenance, Artificial intelligence, {PdM}, Systematic literature review},
	file = {ScienceDirect Full Text PDF:/home/louis/Zotero/storage/T9Y577CR/Carvalho et al. - 2019 - A systematic literature review of machine learning.pdf:application/pdf;ScienceDirect Snapshot:/home/louis/Zotero/storage/S4B2FSEM/S0360835219304838.html:text/html},
}

@article{lasi_industry_2014,
	title = {Industry 4.0},
	volume = {6},
	issn = {1867-0202},
	url = {https://doi.org/10.1007/s12599-014-0334-4},
	doi = {10.1007/s12599-014-0334-4},
	pages = {239--242},
	number = {4},
	journaltitle = {Business \& Information Systems Engineering},
	shortjournal = {Bus Inf Syst Eng},
	author = {Lasi, Heiner and Fettke, Peter and Kemper, Hans-Georg and Feld, Thomas and Hoffmann, Michael},
	urldate = {2023-12-19},
	date = {2014-08-01},
	langid = {english},
	keywords = {Business Intelligence, Enterprise Resource Planning System, Industrial Revolution, Manufacturing System, Product Service System},
	file = {Full Text PDF:/home/louis/Zotero/storage/UXXN553R/Lasi et al. - 2014 - Industry 4.0.pdf:application/pdf},
}

@article{zhao_deep_2019,
	title = {Deep learning and its applications to machine health monitoring},
	volume = {115},
	issn = {0888-3270},
	url = {https://www.sciencedirect.com/science/article/pii/S0888327018303108},
	doi = {10.1016/j.ymssp.2018.05.050},
	abstract = {Since 2006, deep learning ({DL}) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder ({AE}) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network ({DBN}) and Deep Boltzmann Machines ({DBM}), Convolutional Neural Networks ({CNN}) and Recurrent Neural Networks ({RNN}). In addition, an experimental study on the performances of these approaches has been conducted, in which the data and code have been online. Finally, some new trends of {DL}-based machine health monitoring methods are discussed.},
	pages = {213--237},
	journaltitle = {Mechanical Systems and Signal Processing},
	shortjournal = {Mechanical Systems and Signal Processing},
	author = {Zhao, Rui and Yan, Ruqiang and Chen, Zhenghua and Mao, Kezhi and Wang, Peng and Gao, Robert X.},
	urldate = {2023-12-19},
	date = {2019-01-15},
	keywords = {Big data, Deep learning, Machine health monitoring},
	file = {ScienceDirect Snapshot:/home/louis/Zotero/storage/LEHBJFE8/S0888327018303108.html:text/html},
}

@article{zonta_predictive_2020,
	title = {Predictive maintenance in the Industry 4.0: A systematic literature review},
	volume = {150},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835220305787},
	doi = {10.1016/j.cie.2020.106889},
	shorttitle = {Predictive maintenance in the Industry 4.0},
	abstract = {Industry 4.0 is collaborating directly for the technological revolution. Both machines and managers are daily confronted with decision making involving a massive input of data and customization in the manufacturing process. The ability to predict the need for maintenance of assets at a specific future moment is one of the main challenges in this scope. The possibility of performing predictive maintenance contributes to enhancing machine downtime, costs, control, and quality of production. We observed that surveys and tutorials about Industry 4.0 focus mainly on addressing data analytics and machine learning methods to change production procedures, so not comprising predictive maintenance methods and their organization. In this context, this article presents a systematic literature review of initiatives of predictive maintenance in Industry 4.0, identifying and cataloging methods, standards, and applications. As the main contributions, this survey discusses the current challenges and limitations in predictive maintenance, in addition to proposing a novel taxonomy to classify this research area considering the needs of the Industry 4.0. We concluded that computer science, including artificial intelligence and distributed computing fields, is more and more present in an area where engineering was the dominant expertise, so detaching the importance of a multidisciplinary approach to address Industry 4.0 effectively.},
	pages = {106889},
	journaltitle = {Computers \& Industrial Engineering},
	shortjournal = {Computers \& Industrial Engineering},
	author = {Zonta, Tiago and da Costa, Cristiano André and da Rosa Righi, Rodrigo and de Lima, Miromar José and da Trindade, Eduardo Silveira and Li, Guann Pyng},
	urldate = {2023-12-19},
	date = {2020-12-01},
	keywords = {Artificial intelligence, Conditional-based maintenance, Industry 4.0, Predictive Maintenance, Remaining Useful Life},
	file = {ScienceDirect Snapshot:/home/louis/Zotero/storage/TBTPZFN8/S0360835220305787.html:text/html},
}

@online{noauthor_time_nodate,
	title = {Time Series Analysis - James D. Hamilton - Google Books},
	url = {https://books.google.de/books?hl=de&lr=&id=BeryDwAAQBAJ&oi=fnd&pg=PP1&dq=time+series+analysis&ots=BhwRaZaXin&sig=cGLVE7rPH1fkmjaG4vadn7BRY6w#v=onepage&q=time%20series%20analysis&f=false},
	urldate = {2023-12-29},
	file = {Time Series Analysis - James D. Hamilton - Google Books:/home/louis/Zotero/storage/D6CX2G3U/books.html:text/html},
}

@article{lin_time_2019,
	title = {Time Series Prediction Algorithm for Intelligent Predictive Maintenance},
	volume = {4},
	issn = {2377-3766},
	url = {https://ieeexplore.ieee.org/abstract/document/8721101},
	doi = {10.1109/LRA.2019.2918684},
	abstract = {Predictive maintenance aims to find out when the target device ({TD}) is in the sick state and almost entering the dead state before its actual occurrence to conduct just-in-time maintenance, so as to avoid unexpected {TD} down time. In this way, not only tool availability and manufacturing quality are improved, but the additional cost of excessive maintenance in preventive maintenance strategy can also be reduced. Among the predictive maintenance technologies proposed by many scholars, exponential model was commonly applied to predict the remaining useful life ({RUL}) of {TD}. However, due to the algorithm limitations, when {TD} is about to die, whether the {TD}'s aging feature suddenly rises or becomes smooth, the exponential model may not be able to keep up with the real-time prediction or even falsely predicts long {RUL}. To solve the problem of inaccurate {RUL} prediction, the authors propose the time series prediction ({TSP}) algorithm. {TSP} applies the time series analysis model built by information criterion to adapt to the complicated future trend of solving {TD} fault prediction. Also, the Pre-Alarm Module ({PreAM}) to make alert of immediate maintenance when a {TD} is likely to shut down shortly as well as the Death Correlation Index ({DCI}) to reveal the possibility of entering the dead state are proposed in this work. How to select the most effective predictors and adjust the predictor weights to construct high-performance prediction model are also illustrated in this letter with the tools in various industries (such as solar-cell manufacturing and machine tool industry) being the examples of the {TSP} algorithm.},
	pages = {2807--2814},
	number = {3},
	journaltitle = {{IEEE} Robotics and Automation Letters},
	author = {Lin, Chin-Yi and Hsieh, Yu-Ming and Cheng, Fan-Tien and Huang, Hsien-Cheng and Adnan, Muhammad},
	urldate = {2023-12-29},
	date = {2019-07},
	note = {Conference Name: {IEEE} Robotics and Automation Letters},
	file = {IEEE Xplore Abstract Record:/home/louis/Zotero/storage/TUXK7N2R/8721101.html:text/html;IEEE Xplore Full Text PDF:/home/louis/Zotero/storage/SYZ2YECJ/Lin et al. - 2019 - Time Series Prediction Algorithm for Intelligent Predictive Maintenance.pdf:application/pdf},
}

@article{lie_algorithm_1986,
	title = {An Algorithm for Preventive Maintenance Policy},
	volume = {35},
	issn = {1558-1721},
	url = {https://ieeexplore.ieee.org/abstract/document/4335352},
	doi = {10.1109/TR.1986.4335352},
	abstract = {Simple preventive maintenance (Maintenance type 1P) and preventive replacement (maintenance type 2P) are scheduled in such a way that the system does not drop below a minimum reliability. Failure rate after maintenance type 1P lies between "good as new" and "bad as old". The degree of improvement in failure rate after maintenance type 1P is cailed the improvement factor. A set of curves for the improvement factor as a function of cost for maintenance type 1P and age of the system is proposed. The cost rate for a system is formulated as a ratio of an average cost for a cycle (time between replacements) to an average cycle length. An optimum number of type 1P maintenance actions before type 2P maintenance is obtained by minimizing the cost rate when the failure times are Weibull distributed. The optimum solutions are a function of improvement factors and predetermined upper limit of failure rate.},
	pages = {71--75},
	number = {1},
	journaltitle = {{IEEE} Transactions on Reliability},
	author = {Lie, Chang Hoon and Chun, Young Ho},
	urldate = {2023-12-29},
	date = {1986-04},
	note = {Conference Name: {IEEE} Transactions on Reliability},
	file = {IEEE Xplore Abstract Record:/home/louis/Zotero/storage/QADUQCVG/4335352.html:text/html;IEEE Xplore Full Text PDF:/home/louis/Zotero/storage/44AVZXK2/Lie and Chun - 1986 - An Algorithm for Preventive Maintenance Policy.pdf:application/pdf},
}

@article{fu_review_2011,
	title = {A review on time series data mining},
	volume = {24},
	issn = {0952-1976},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197610001727},
	doi = {10.1016/j.engappai.2010.09.007},
	abstract = {Time series is an important class of temporal data objects and it can be easily obtained from scientific and financial applications. A time series is a collection of observations made chronologically. The nature of time series data includes: large in data size, high dimensionality and necessary to update continuously. Moreover time series data, which is characterized by its numerical and continuous nature, is always considered as a whole instead of individual numerical field. The increasing use of time series data has initiated a great deal of research and development attempts in the field of data mining. The abundant research on time series data mining in the last decade could hamper the entry of interested researchers, due to its complexity. In this paper, a comprehensive revision on the existing time series data mining research is given. They are generally categorized into representation and indexing, similarity measure, segmentation, visualization and mining. Moreover state-of-the-art research issues are also highlighted. The primary objective of this paper is to serve as a glossary for interested researchers to have an overall picture on the current time series data mining development and identify their potential research direction to further investigation.},
	pages = {164--181},
	number = {1},
	journaltitle = {Engineering Applications of Artificial Intelligence},
	shortjournal = {Engineering Applications of Artificial Intelligence},
	author = {Fu, Tak-chung},
	urldate = {2023-12-29},
	date = {2011-02-01},
	keywords = {Representation, Segmentation, Similarity measure, Time series data mining, Visualization},
	file = {ScienceDirect Snapshot:/home/louis/Zotero/storage/CW6TS85I/S0952197610001727.html:text/html},
}

@online{vaswani_attention_2017,
	title = {Attention Is All You Need},
	url = {https://arxiv.org/abs/1706.03762v7},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	titleaddon = {{arXiv}.org},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	urldate = {2024-01-02},
	date = {2017-06-12},
	langid = {english},
	file = {Full Text PDF:/home/louis/Zotero/storage/XESWJFNH/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf},
}

@online{wen_transformers_2022,
	title = {Transformers in Time Series: A Survey},
	url = {https://arxiv.org/abs/2202.07125v5},
	shorttitle = {Transformers in Time Series},
	abstract = {Transformers have achieved superior performances in many tasks in natural language processing and computer vision, which also triggered great interest in the time series community. Among multiple advantages of Transformers, the ability to capture long-range dependencies and interactions is especially attractive for time series modeling, leading to exciting progress in various time series applications. In this paper, we systematically review Transformer schemes for time series modeling by highlighting their strengths as well as limitations. In particular, we examine the development of time series Transformers in two perspectives. From the perspective of network structure, we summarize the adaptations and modifications that have been made to Transformers in order to accommodate the challenges in time series analysis. From the perspective of applications, we categorize time series Transformers based on common tasks including forecasting, anomaly detection, and classification. Empirically, we perform robust analysis, model size analysis, and seasonal-trend decomposition analysis to study how Transformers perform in time series. Finally, we discuss and suggest future directions to provide useful research guidance. To the best of our knowledge, this paper is the first work to comprehensively and systematically summarize the recent advances of Transformers for modeling time series data. We hope this survey will ignite further research interests in time series Transformers.},
	titleaddon = {{arXiv}.org},
	author = {Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
	urldate = {2024-01-02},
	date = {2022-02-15},
	langid = {english},
	file = {Full Text PDF:/home/louis/Zotero/storage/WPIRWGFD/Wen et al. - 2022 - Transformers in Time Series A Survey.pdf:application/pdf},
}

@online{sun_retentive_2023,
	title = {Retentive Network: A Successor to Transformer for Large Language Models},
	url = {https://arxiv.org/abs/2307.08621v4},
	shorttitle = {Retentive Network},
	abstract = {In this work, we propose Retentive Network ({RetNet}) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost \$O(1)\$ inference, which improves decoding throughput, latency, and {GPU} memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that {RetNet} achieves favorable scaling results, parallel training, low-cost deployment, and efficient inference. The intriguing properties make {RetNet} a strong successor to Transformer for large language models. Code will be available at https://aka.ms/retnet.},
	titleaddon = {{arXiv}.org},
	author = {Sun, Yutao and Dong, Li and Huang, Shaohan and Ma, Shuming and Xia, Yuqing and Xue, Jilong and Wang, Jianyong and Wei, Furu},
	urldate = {2024-01-02},
	date = {2023-07-17},
	langid = {english},
	file = {Full Text PDF:/home/louis/Zotero/storage/4QZZPG4C/Sun et al. - 2023 - Retentive Network A Successor to Transformer for Large Language Models.pdf:application/pdf},
}

@article{ismail_fawaz_deep_2019,
	title = {Deep learning for time series classification: a review},
	volume = {33},
	issn = {1573-756X},
	url = {https://doi.org/10.1007/s10618-019-00619-1},
	doi = {10.1007/s10618-019-00619-1},
	shorttitle = {Deep learning for time series classification},
	abstract = {Time Series Classification ({TSC}) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of {TSC} algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks ({DNNs}) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. {DNNs} have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with {DNNs} to reach state-of-the-art performance for document classification and speech recognition. In this article, we study the current state-of-the-art performance of deep learning algorithms for {TSC} by presenting an empirical study of the most recent {DNN} architectures for {TSC}. We give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of {DNNs} for {TSC}. We also provide an open source deep learning framework to the {TSC} community where we implemented each of the compared approaches and evaluated them on a univariate {TSC} benchmark (the {UCR}/{UEA} archive) and 12 multivariate time series datasets. By training 8730 deep learning models on 97 time series datasets, we propose the most exhaustive study of {DNNs} for {TSC} to date.},
	pages = {917--963},
	number = {4},
	journaltitle = {Data Mining and Knowledge Discovery},
	shortjournal = {Data Min Knowl Disc},
	author = {Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	urldate = {2023-12-29},
	date = {2019-07-01},
	langid = {english},
	keywords = {Time series, Deep learning, Classification, Review},
	file = {Full Text PDF:/home/louis/Zotero/storage/YTH3HEHH/Ismail Fawaz et al. - 2019 - Deep learning for time series classification a review.pdf:application/pdf},
}

@article{makridakis_m5_results_2022,
	title = {The M5 uncertainty competition: Results, findings and conclusions},
	volume = {38},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207021001722},
	doi = {10.1016/j.ijforecast.2021.10.009},
	series = {Special Issue: M5 competition},
	shorttitle = {The M5 uncertainty competition},
	abstract = {This paper describes the M5 “Uncertainty” competition, the second of two parallel challenges of the latest M competition, aiming to advance the theory and practice of forecasting. The particular objective of the M5 “Uncertainty” competition was to accurately forecast the uncertainty distributions of the realized values of 42,840 time series that represent the hierarchical unit sales of the largest retail company in the world by revenue, Walmart. To do so, the competition required the prediction of nine different quantiles (0.005, 0.025, 0.165, 0.250, 0.500, 0.750, 0.835, 0.975, and 0.995), that can sufficiently describe the complete distributions of future sales. The paper provides details on the implementation and execution of the M5 “Uncertainty” competition, presents its results and the top-performing methods, and summarizes its major findings and conclusions. Finally, it discusses the implications of its findings and suggests directions for future research.},
	pages = {1365--1385},
	number = {4},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios and Chen, Zhi and Gaba, Anil and Tsetlin, Ilia and Winkler, Robert L.},
	urldate = {2023-12-29},
	date = {2022-10-01},
	keywords = {Machine learning, Time series, Forecasting competitions, M competitions, Probabilistic forecasts, Retail sales forecasting, Uncertainty},
	file = {ScienceDirect Snapshot:/home/louis/Zotero/storage/VM529ZB7/S0169207021001722.html:text/html},
}

@article{aghabozorgi_time-series_2015,
	title = {Time-series clustering – A decade review},
	volume = {53},
	issn = {0306-4379},
	url = {https://www.sciencedirect.com/science/article/pii/S0306437915000733},
	doi = {10.1016/j.is.2015.04.007},
	abstract = {Clustering is a solution for classifying enormous data when there is not any early knowledge about classes. With emerging new concepts like cloud computing and big data and their vast applications in recent years, research works have been increased on unsupervised solutions like clustering algorithms to extract knowledge from this avalanche of data. Clustering time-series data has been used in diverse scientific areas to discover patterns which empower data analysts to extract valuable information from complex and massive datasets. In case of huge datasets, using supervised classification solutions is almost impossible, while clustering can solve this problem using un-supervised approaches. In this research work, the focus is on time-series data, which is one of the popular data types in clustering problems and is broadly used from gene expression data in biology to stock market analysis in finance. This review will expose four main components of time-series clustering and is aimed to represent an updated investigation on the trend of improvements in efficiency, quality and complexity of clustering time-series approaches during the last decade and enlighten new paths for future works.},
	pages = {16--38},
	journaltitle = {Information Systems},
	shortjournal = {Information Systems},
	author = {Aghabozorgi, Saeed and Seyed Shirkhorshidi, Ali and Ying Wah, Teh},
	urldate = {2023-12-29},
	date = {2015-10-01},
	keywords = {Clustering, Distance measure, Evaluation measure, Representations, Time-series},
	file = {ScienceDirect Snapshot:/home/louis/Zotero/storage/R3B6WZBA/S0306437915000733.html:text/html},
}

@article{esling_time-series_2012,
	title = {Time-series data mining},
	volume = {45},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/2379776.2379788},
	doi = {10.1145/2379776.2379788},
	abstract = {In almost every scientific field, measurements are performed over time. These observations lead to a collection of organized data called time series. The purpose of time-series data mining is to try to extract all meaningful knowledge from the shape of data. Even if humans have a natural capacity to perform these tasks, it remains a complex problem for computers. In this article we intend to provide a survey of the techniques applied for time-series data mining. The first part is devoted to an overview of the tasks that have captured most of the interest of researchers. Considering that in most cases, time-series task relies on the same components for implementation, we divide the literature depending on these common aspects, namely representation techniques, distance measures, and indexing methods. The study of the relevant literature has been categorized for each individual aspects. Four types of robustness could then be formalized and any kind of distance could then be classified. Finally, the study submits various research trends and avenues that can be explored in the near future. We hope that this article can provide a broad and deep understanding of the time-series data mining research field.},
	pages = {12:1--12:34},
	number = {1},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Esling, Philippe and Agon, Carlos},
	urldate = {2024-01-02},
	date = {2012},
	keywords = {data indexing, data mining, Distance measures, query by content, sequence matching, similarity measures, stream analysis, temporal analysis, time series},
	file = {Full Text PDF:/home/louis/Zotero/storage/QCWFJRJD/Esling and Agon - 2012 - Time-series data mining.pdf:application/pdf},
}

@article{makridakis_m5_background_2022,
	title = {The M5 competition: Background, organization, and implementation},
	volume = {38},
	issn = {01692070},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207021001187},
	doi = {10.1016/j.ijforecast.2021.07.007},
	shorttitle = {The M5 competition},
	abstract = {The M5 competition follows the previous four M competitions, whose purpose is to learn from empirical evidence how to improve forecasting performance and advance the theory and practice of forecasting. M5 focused on a retail sales forecasting application with the objective to produce the most accurate point forecasts for 42,840 time series that represent the hierarchical unit sales of the largest retail company in the world, Walmart, as well as to provide the most accurate estimates of the uncertainty of these forecasts. Hence, the competition consisted of two parallel challenges, namely the Accuracy and Uncertainty forecasting competitions. M5 extended the results of the previous M competitions by: (a) significantly expanding the number of participating methods, especially those in the category of machine learning; (b) evaluating the performance of the uncertainty distribution along with point forecast accuracy; (c) including exogenous/explanatory variables in addition to the time series data; (d) using grouped, correlated time series; and (e) focusing on series that display intermittency. This paper describes the background, organization, and implementations of the competition, and it presents the data used and their characteristics. Consequently, it serves as introductory material to the results of the two forecasting challenges to facilitate their understanding. © 2021 The Authors. Published by Elsevier B.V. on behalf of International Institute of Forecasters. This is an open access article under the {CC} {BY} license (http://creativecommons.org/licenses/by/4.0/).},
	pages = {1325--1336},
	number = {4},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
	urldate = {2024-01-02},
	date = {2022-10},
	langid = {english},
	file = {Makridakis et al. - 2022 - The M5 competition Background, organization, and implementation.pdf:/home/louis/Zotero/storage/JNIMS4VN/Makridakis et al. - 2022 - The M5 competition Background, organization, and implementation.pdf:application/pdf},
}

@inproceedings{ke_lightgbm_2017,
	title = {{LightGBM}: A Highly Efficient Gradient Boosting Decision Tree},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html},
	shorttitle = {{LightGBM}},
	abstract = {Gradient Boosting Decision Tree ({GBDT}) is a popular machine learning algorithm, and has quite a few effective implementations such as {XGBoost} and {pGBRT}. Although many engineering optimizations have been adopted in these implementations, the efficiency and scalability are still unsatisfactory when the feature dimension is high and data size is large. A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. To tackle this problem, we propose two novel techniques: {\textbackslash}emph\{Gradient-based One-Side Sampling\} ({GOSS}) and {\textbackslash}emph\{Exclusive Feature Bundling\} ({EFB}). With {GOSS}, we exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. We prove that, since the data instances with larger gradients play a more important role in the computation of information gain, {GOSS} can obtain quite accurate estimation of the information gain with a much smaller data size. With {EFB}, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features. We prove that finding the optimal bundling of exclusive features is {NP}-hard, but a greedy algorithm can achieve quite good approximation ratio (and thus can effectively reduce the number of features without hurting the accuracy of split point determination by much). We call our new {GBDT} implementation with {GOSS} and {EFB} {\textbackslash}emph\{{LightGBM}\}. Our experiments on multiple public datasets show that, {LightGBM} speeds up the training process of conventional {GBDT} by up to over 20 times while achieving almost the same accuracy.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
	urldate = {2024-01-02},
	date = {2017},
	file = {Full Text PDF:/home/louis/Zotero/storage/H6CLKX3K/Ke et al. - 2017 - LightGBM A Highly Efficient Gradient Boosting Decision Tree.pdf:application/pdf},
}

@article{chen_xgboost_nodate,
	title = {xgboost: {eXtreme} Gradient Boosting},
	author = {Chen, Tianqi and He, Tong},
	langid = {english},
	file = {Chen and He - xgboost eXtreme Gradient Boosting.pdf:/home/louis/Zotero/storage/5WM42BLV/Chen and He - xgboost eXtreme Gradient Boosting.pdf:application/pdf},
}
